{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import dataloader\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support,classification_report,accuracy_score\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split,KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = ['0', '1', '2', '3']  \n",
    "CLASS_INTEGERS = np.array([0, 1, 2, 3])\n",
    "# CLASS_NAMES = ['closed', 'open']  \n",
    "# CLASS_INTEGERS = np.array([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(X_, y_):\n",
    "    N   = X_.shape[0]\n",
    "    N_f = X_.shape[1]\n",
    "    data = []\n",
    "\n",
    "    for i in range(N):\n",
    "        feat = X_[i, :]\n",
    "        label = float(y_[i])\n",
    "        data.append((feat, label))\n",
    "\n",
    "    random.shuffle(data)\n",
    "\n",
    "    #rebuild X and y\n",
    "    X =  np.zeros((N, N_f))\n",
    "    y = -np.ones((N,)) #negative value to audit ingress code\n",
    "\n",
    "    for i in range(N):\n",
    "        X_1, y_1 = data[i]\n",
    "        X[i, :] = X_1\n",
    "        y[i]    = y_1\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df,label_column = 0):\n",
    "    df.columns = [str(i) for i in range(df.shape[1])]\n",
    "    if label_column:\n",
    "        df.rename(columns={'0':'Filename',str(label_column):'label'},inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.068013</td>\n",
       "      <td>0.099099</td>\n",
       "      <td>0.063168</td>\n",
       "      <td>-0.033925</td>\n",
       "      <td>-0.115523</td>\n",
       "      <td>0.029493</td>\n",
       "      <td>0.020863</td>\n",
       "      <td>-0.127556</td>\n",
       "      <td>0.183850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080963</td>\n",
       "      <td>0.072025</td>\n",
       "      <td>-0.007075</td>\n",
       "      <td>-0.105849</td>\n",
       "      <td>-0.113559</td>\n",
       "      <td>-0.057625</td>\n",
       "      <td>0.010671</td>\n",
       "      <td>-0.040322</td>\n",
       "      <td>0.044271</td>\n",
       "      <td>0.027354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.063961</td>\n",
       "      <td>0.058431</td>\n",
       "      <td>0.070932</td>\n",
       "      <td>0.029915</td>\n",
       "      <td>-0.075097</td>\n",
       "      <td>0.026910</td>\n",
       "      <td>-0.035000</td>\n",
       "      <td>-0.097112</td>\n",
       "      <td>0.153792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050051</td>\n",
       "      <td>0.084680</td>\n",
       "      <td>-0.018112</td>\n",
       "      <td>-0.105976</td>\n",
       "      <td>-0.173478</td>\n",
       "      <td>-0.078253</td>\n",
       "      <td>-0.023061</td>\n",
       "      <td>-0.033837</td>\n",
       "      <td>0.003364</td>\n",
       "      <td>0.051408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.031547</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.039548</td>\n",
       "      <td>-0.019090</td>\n",
       "      <td>-0.099739</td>\n",
       "      <td>0.020485</td>\n",
       "      <td>-0.018248</td>\n",
       "      <td>-0.065166</td>\n",
       "      <td>0.200186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049710</td>\n",
       "      <td>0.094621</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>-0.127226</td>\n",
       "      <td>-0.188725</td>\n",
       "      <td>-0.052428</td>\n",
       "      <td>-0.014780</td>\n",
       "      <td>-0.003984</td>\n",
       "      <td>-0.018441</td>\n",
       "      <td>0.075985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.036490</td>\n",
       "      <td>0.018377</td>\n",
       "      <td>0.064510</td>\n",
       "      <td>-0.044817</td>\n",
       "      <td>-0.071073</td>\n",
       "      <td>0.044935</td>\n",
       "      <td>-0.024089</td>\n",
       "      <td>-0.118739</td>\n",
       "      <td>0.148862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062219</td>\n",
       "      <td>0.104761</td>\n",
       "      <td>-0.033573</td>\n",
       "      <td>-0.139892</td>\n",
       "      <td>-0.196840</td>\n",
       "      <td>-0.063598</td>\n",
       "      <td>0.016169</td>\n",
       "      <td>-0.002625</td>\n",
       "      <td>-0.005354</td>\n",
       "      <td>0.060359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.102252</td>\n",
       "      <td>0.073458</td>\n",
       "      <td>0.058132</td>\n",
       "      <td>-0.115190</td>\n",
       "      <td>-0.102493</td>\n",
       "      <td>0.070953</td>\n",
       "      <td>-0.048466</td>\n",
       "      <td>-0.086006</td>\n",
       "      <td>0.235441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100441</td>\n",
       "      <td>0.093152</td>\n",
       "      <td>-0.033645</td>\n",
       "      <td>-0.075337</td>\n",
       "      <td>-0.132855</td>\n",
       "      <td>-0.022089</td>\n",
       "      <td>0.039518</td>\n",
       "      <td>-0.030403</td>\n",
       "      <td>0.052154</td>\n",
       "      <td>0.049830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label         1         2         3         4         5         6  \\\n",
       "0      0 -0.068013  0.099099  0.063168 -0.033925 -0.115523  0.029493   \n",
       "1      0 -0.063961  0.058431  0.070932  0.029915 -0.075097  0.026910   \n",
       "2      0 -0.031547  0.009766  0.039548 -0.019090 -0.099739  0.020485   \n",
       "3      0 -0.036490  0.018377  0.064510 -0.044817 -0.071073  0.044935   \n",
       "4      0 -0.102252  0.073458  0.058132 -0.115190 -0.102493  0.070953   \n",
       "\n",
       "          7         8         9    ...          119       120       121  \\\n",
       "0  0.020863 -0.127556  0.183850    ...     0.080963  0.072025 -0.007075   \n",
       "1 -0.035000 -0.097112  0.153792    ...     0.050051  0.084680 -0.018112   \n",
       "2 -0.018248 -0.065166  0.200186    ...     0.049710  0.094621  0.002008   \n",
       "3 -0.024089 -0.118739  0.148862    ...     0.062219  0.104761 -0.033573   \n",
       "4 -0.048466 -0.086006  0.235441    ...     0.100441  0.093152 -0.033645   \n",
       "\n",
       "        122       123       124       125       126       127       128  \n",
       "0 -0.105849 -0.113559 -0.057625  0.010671 -0.040322  0.044271  0.027354  \n",
       "1 -0.105976 -0.173478 -0.078253 -0.023061 -0.033837  0.003364  0.051408  \n",
       "2 -0.127226 -0.188725 -0.052428 -0.014780 -0.003984 -0.018441  0.075985  \n",
       "3 -0.139892 -0.196840 -0.063598  0.016169 -0.002625 -0.005354  0.060359  \n",
       "4 -0.075337 -0.132855 -0.022089  0.039518 -0.030403  0.052154  0.049830  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = preprocess_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['0'] = le.fit_transform(df['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.rename(columns={\"0\":\"label\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns=[\"129\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,1:]\n",
    "Y = df.iloc[:,0]\n",
    "Y = pd.DataFrame(Y,columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = shuffle_data(X.values,Y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2291, 128)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train, X_valid, y_Train, y_valid = train_test_split(X, Y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1832, 128)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth' : 8, 'eta' : 0.1, 'nthread' : 18}\n",
    "param['objective'] = 'multi:softmax'\n",
    "param['eval_metric'] = \"merror\"\n",
    "param['num_class'] =  4\n",
    "param['num_boost_round'] = 70\n",
    "\n",
    "plst = param.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets build and save a vanilla XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Building and saving a model'''\n",
    "plst = param.items()\n",
    "dtrain = xgb.DMatrix(X_Train, label=y_Train)\n",
    "bst = xgb.train(params=plst,dtrain=dtrain,num_boost_round=param['num_boost_round'],verbose_eval=2)\n",
    "ver = 1.0\n",
    "bst.save_model('xgb_ver_{}_depth_{}_eta_{}_num_round_{}_release_model_final.model'.format(ver,param['max_depth'],param['eta'],param['num_boost_round']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.Booster()\n",
    "bst.load_model('xgb_ver_1.0_depth_8_eta_0.1_num_round_70_release_model_final.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bst.predict(xgb.DMatrix(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(91.68,0.5,'true value')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = confusion_matrix(y_pred,y_valid)\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "\n",
    "plt.xticks(CLASS_INTEGERS + 0.5, CLASS_NAMES) # add half for nicer location\n",
    "plt.yticks(CLASS_INTEGERS + 0.5, CLASS_NAMES,  rotation='horizontal') # add half for nicer location\n",
    "\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.79      0.88        14\n",
      "        1.0       0.99      0.99      0.99       156\n",
      "        2.0       0.98      0.84      0.91        70\n",
      "        3.0       0.94      1.00      0.97       219\n",
      "\n",
      "avg / total       0.97      0.97      0.96       459\n",
      "\n",
      "Accuracy score : 0.9651416122\n"
     ]
    }
   ],
   "source": [
    "score = classification_report(y_valid,y_pred)\n",
    "print(score)\n",
    "print(\"Accuracy score : {}\".format(accuracy_score(y_valid,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_absolute(param,X,y,X_test,y_test):\n",
    "    \n",
    "    plst = param.items()\n",
    "    \n",
    "    num_boost_rounds = param['num_boost_round']\n",
    "    \n",
    "    score_training = 0\n",
    "    score_testing = 0\n",
    "\n",
    "    X_train, X_test = X, X_test\n",
    "    y_train, y_test = y, y_test\n",
    "    \n",
    "    print(\"Train size : {} Test Size = {}\".format(X_train.shape[0],X_test.shape[0]))\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    bst = xgb.train(params=plst,dtrain=dtrain,num_boost_round=num_boost_rounds,verbose_eval=2)\n",
    "\n",
    "    y_train_pred = bst.predict(xgb.DMatrix(X_train))\n",
    "    score = classification_report(y_train,y_train_pred)\n",
    "\n",
    "    score_training += accuracy_score(y_train,y_train_pred)\n",
    "\n",
    "    y_pred = bst.predict(xgb.DMatrix(X_test))\n",
    "    score = classification_report(y_test,y_pred)\n",
    "\n",
    "    score_testing += accuracy_score(y_test,y_pred)\n",
    "\n",
    "    return score_training , score_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_arr = [7,8,9,10,11,12]\n",
    "eta_arr = [0.05,0.1,0.2,0.3]\n",
    "num_rounds_arr = [50,55,60,65,70,75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_res_3_0_pareto = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets Go through the Hyperparameter tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 8, 9, 10, 11, 12]\n",
      "[0.05, 0.1, 0.2, 0.3]\n",
      "[50, 55, 60, 65, 70, 75]\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.05 num_round = 50\n",
      "training_depth_7_eta_0.05_num_boost_round_50_3_0_with_degenerate score 0.999454148472\n",
      "testing_depth_7_eta_0.05_num_boost_round_50_3_0_with_degenerate score 0.954248366013\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.05 num_round = 55\n",
      "training_depth_7_eta_0.05_num_boost_round_55_3_0_with_degenerate score 0.999454148472\n",
      "testing_depth_7_eta_0.05_num_boost_round_55_3_0_with_degenerate score 0.956427015251\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.05 num_round = 60\n",
      "training_depth_7_eta_0.05_num_boost_round_60_3_0_with_degenerate score 1.0\n",
      "testing_depth_7_eta_0.05_num_boost_round_60_3_0_with_degenerate score 0.956427015251\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.05 num_round = 65\n",
      "training_depth_7_eta_0.05_num_boost_round_65_3_0_with_degenerate score 1.0\n",
      "testing_depth_7_eta_0.05_num_boost_round_65_3_0_with_degenerate score 0.958605664488\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.05 num_round = 70\n",
      "training_depth_7_eta_0.05_num_boost_round_70_3_0_with_degenerate score 1.0\n",
      "testing_depth_7_eta_0.05_num_boost_round_70_3_0_with_degenerate score 0.960784313725\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.05 num_round = 75\n",
      "training_depth_7_eta_0.05_num_boost_round_75_3_0_with_degenerate score 1.0\n",
      "testing_depth_7_eta_0.05_num_boost_round_75_3_0_with_degenerate score 0.958605664488\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.1 num_round = 50\n",
      "training_depth_7_eta_0.1_num_boost_round_50_3_0_with_degenerate score 1.0\n",
      "testing_depth_7_eta_0.1_num_boost_round_50_3_0_with_degenerate score 0.958605664488\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.1 num_round = 55\n",
      "training_depth_7_eta_0.1_num_boost_round_55_3_0_with_degenerate score 1.0\n",
      "testing_depth_7_eta_0.1_num_boost_round_55_3_0_with_degenerate score 0.958605664488\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.1 num_round = 60\n",
      "training_depth_7_eta_0.1_num_boost_round_60_3_0_with_degenerate score 1.0\n",
      "testing_depth_7_eta_0.1_num_boost_round_60_3_0_with_degenerate score 0.960784313725\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.1 num_round = 65\n",
      "training_depth_7_eta_0.1_num_boost_round_65_3_0_with_degenerate score 1.0\n",
      "testing_depth_7_eta_0.1_num_boost_round_65_3_0_with_degenerate score 0.9651416122\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.1 num_round = 70\n",
      "training_depth_7_eta_0.1_num_boost_round_70_3_0_with_degenerate score 1.0\n",
      "testing_depth_7_eta_0.1_num_boost_round_70_3_0_with_degenerate score 0.9651416122\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.1 num_round = 75\n",
      "training_depth_7_eta_0.1_num_boost_round_75_3_0_with_degenerate score 1.0\n",
      "testing_depth_7_eta_0.1_num_boost_round_75_3_0_with_degenerate score 0.9651416122\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.2 num_round = 50\n",
      "training_depth_7_eta_0.2_num_boost_round_50_3_0_with_degenerate score 1.0\n",
      "testing_depth_7_eta_0.2_num_boost_round_50_3_0_with_degenerate score 0.971677559913\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.2 num_round = 55\n",
      "training_depth_7_eta_0.2_num_boost_round_55_3_0_with_degenerate score 1.0\n",
      "testing_depth_7_eta_0.2_num_boost_round_55_3_0_with_degenerate score 0.971677559913\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.2 num_round = 60\n",
      "training_depth_7_eta_0.2_num_boost_round_60_3_0_with_degenerate score 1.0\n",
      "testing_depth_7_eta_0.2_num_boost_round_60_3_0_with_degenerate score 0.971677559913\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.2 num_round = 65\n",
      "training_depth_7_eta_0.2_num_boost_round_65_3_0_with_degenerate score 1.0\n",
      "testing_depth_7_eta_0.2_num_boost_round_65_3_0_with_degenerate score 0.97385620915\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.2 num_round = 70\n",
      "training_depth_7_eta_0.2_num_boost_round_70_3_0_with_degenerate score 1.0\n",
      "testing_depth_7_eta_0.2_num_boost_round_70_3_0_with_degenerate score 0.97385620915\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.2 num_round = 75\n",
      "training_depth_7_eta_0.2_num_boost_round_75_3_0_with_degenerate score 1.0\n",
      "testing_depth_7_eta_0.2_num_boost_round_75_3_0_with_degenerate score 0.97385620915\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.3 num_round = 50\n",
      "training_depth_7_eta_0.3_num_boost_round_50_3_0_with_degenerate score 1.0\n",
      "testing_depth_7_eta_0.3_num_boost_round_50_3_0_with_degenerate score 0.971677559913\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.3 num_round = 55\n",
      "training_depth_7_eta_0.3_num_boost_round_55_3_0_with_degenerate score 1.0\n",
      "testing_depth_7_eta_0.3_num_boost_round_55_3_0_with_degenerate score 0.971677559913\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.3 num_round = 60\n",
      "training_depth_7_eta_0.3_num_boost_round_60_3_0_with_degenerate score 1.0\n",
      "testing_depth_7_eta_0.3_num_boost_round_60_3_0_with_degenerate score 0.971677559913\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.3 num_round = 65\n",
      "training_depth_7_eta_0.3_num_boost_round_65_3_0_with_degenerate score 1.0\n",
      "testing_depth_7_eta_0.3_num_boost_round_65_3_0_with_degenerate score 0.971677559913\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.3 num_round = 70\n",
      "training_depth_7_eta_0.3_num_boost_round_70_3_0_with_degenerate score 1.0\n",
      "testing_depth_7_eta_0.3_num_boost_round_70_3_0_with_degenerate score 0.971677559913\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 7 eta = 0.3 num_round = 75\n",
      "training_depth_7_eta_0.3_num_boost_round_75_3_0_with_degenerate score 1.0\n",
      "testing_depth_7_eta_0.3_num_boost_round_75_3_0_with_degenerate score 0.97385620915\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.05 num_round = 50\n",
      "training_depth_8_eta_0.05_num_boost_round_50_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.05_num_boost_round_50_3_0_with_degenerate score 0.952069716776\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.05 num_round = 55\n",
      "training_depth_8_eta_0.05_num_boost_round_55_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.05_num_boost_round_55_3_0_with_degenerate score 0.954248366013\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.05 num_round = 60\n",
      "training_depth_8_eta_0.05_num_boost_round_60_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.05_num_boost_round_60_3_0_with_degenerate score 0.954248366013\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.05 num_round = 65\n",
      "training_depth_8_eta_0.05_num_boost_round_65_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.05_num_boost_round_65_3_0_with_degenerate score 0.954248366013\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.05 num_round = 70\n",
      "training_depth_8_eta_0.05_num_boost_round_70_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.05_num_boost_round_70_3_0_with_degenerate score 0.954248366013\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.05 num_round = 75\n",
      "training_depth_8_eta_0.05_num_boost_round_75_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.05_num_boost_round_75_3_0_with_degenerate score 0.958605664488\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.1 num_round = 50\n",
      "training_depth_8_eta_0.1_num_boost_round_50_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.1_num_boost_round_50_3_0_with_degenerate score 0.9651416122\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.1 num_round = 55\n",
      "training_depth_8_eta_0.1_num_boost_round_55_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.1_num_boost_round_55_3_0_with_degenerate score 0.9651416122\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.1 num_round = 60\n",
      "training_depth_8_eta_0.1_num_boost_round_60_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.1_num_boost_round_60_3_0_with_degenerate score 0.9651416122\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.1 num_round = 65\n",
      "training_depth_8_eta_0.1_num_boost_round_65_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.1_num_boost_round_65_3_0_with_degenerate score 0.9651416122\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.1 num_round = 70\n",
      "training_depth_8_eta_0.1_num_boost_round_70_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.1_num_boost_round_70_3_0_with_degenerate score 0.9651416122\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.1 num_round = 75\n",
      "training_depth_8_eta_0.1_num_boost_round_75_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.1_num_boost_round_75_3_0_with_degenerate score 0.9651416122\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.2 num_round = 50\n",
      "training_depth_8_eta_0.2_num_boost_round_50_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.2_num_boost_round_50_3_0_with_degenerate score 0.967320261438\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.2 num_round = 55\n",
      "training_depth_8_eta_0.2_num_boost_round_55_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.2_num_boost_round_55_3_0_with_degenerate score 0.969498910675\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.2 num_round = 60\n",
      "training_depth_8_eta_0.2_num_boost_round_60_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.2_num_boost_round_60_3_0_with_degenerate score 0.969498910675\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.2 num_round = 65\n",
      "training_depth_8_eta_0.2_num_boost_round_65_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.2_num_boost_round_65_3_0_with_degenerate score 0.969498910675\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.2 num_round = 70\n",
      "training_depth_8_eta_0.2_num_boost_round_70_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.2_num_boost_round_70_3_0_with_degenerate score 0.97385620915\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.2 num_round = 75\n",
      "training_depth_8_eta_0.2_num_boost_round_75_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.2_num_boost_round_75_3_0_with_degenerate score 0.97385620915\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.3 num_round = 50\n",
      "training_depth_8_eta_0.3_num_boost_round_50_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.3_num_boost_round_50_3_0_with_degenerate score 0.97385620915\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.3 num_round = 55\n",
      "training_depth_8_eta_0.3_num_boost_round_55_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.3_num_boost_round_55_3_0_with_degenerate score 0.97385620915\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.3 num_round = 60\n",
      "training_depth_8_eta_0.3_num_boost_round_60_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.3_num_boost_round_60_3_0_with_degenerate score 0.97385620915\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.3 num_round = 65\n",
      "training_depth_8_eta_0.3_num_boost_round_65_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.3_num_boost_round_65_3_0_with_degenerate score 0.97385620915\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.3 num_round = 70\n",
      "training_depth_8_eta_0.3_num_boost_round_70_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.3_num_boost_round_70_3_0_with_degenerate score 0.97385620915\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 8 eta = 0.3 num_round = 75\n",
      "training_depth_8_eta_0.3_num_boost_round_75_3_0_with_degenerate score 1.0\n",
      "testing_depth_8_eta_0.3_num_boost_round_75_3_0_with_degenerate score 0.97385620915\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.05 num_round = 50\n",
      "training_depth_9_eta_0.05_num_boost_round_50_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.05_num_boost_round_50_3_0_with_degenerate score 0.949891067538\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.05 num_round = 55\n",
      "training_depth_9_eta_0.05_num_boost_round_55_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.05_num_boost_round_55_3_0_with_degenerate score 0.954248366013\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.05 num_round = 60\n",
      "training_depth_9_eta_0.05_num_boost_round_60_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.05_num_boost_round_60_3_0_with_degenerate score 0.954248366013\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.05 num_round = 65\n",
      "training_depth_9_eta_0.05_num_boost_round_65_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.05_num_boost_round_65_3_0_with_degenerate score 0.954248366013\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.05 num_round = 70\n",
      "training_depth_9_eta_0.05_num_boost_round_70_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.05_num_boost_round_70_3_0_with_degenerate score 0.958605664488\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.05 num_round = 75\n",
      "training_depth_9_eta_0.05_num_boost_round_75_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.05_num_boost_round_75_3_0_with_degenerate score 0.958605664488\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.1 num_round = 50\n",
      "training_depth_9_eta_0.1_num_boost_round_50_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.1_num_boost_round_50_3_0_with_degenerate score 0.960784313725\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.1 num_round = 55\n",
      "training_depth_9_eta_0.1_num_boost_round_55_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.1_num_boost_round_55_3_0_with_degenerate score 0.960784313725\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.1 num_round = 60\n",
      "training_depth_9_eta_0.1_num_boost_round_60_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.1_num_boost_round_60_3_0_with_degenerate score 0.9651416122\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.1 num_round = 65\n",
      "training_depth_9_eta_0.1_num_boost_round_65_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.1_num_boost_round_65_3_0_with_degenerate score 0.9651416122\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.1 num_round = 70\n",
      "training_depth_9_eta_0.1_num_boost_round_70_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.1_num_boost_round_70_3_0_with_degenerate score 0.962962962963\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.1 num_round = 75\n",
      "training_depth_9_eta_0.1_num_boost_round_75_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.1_num_boost_round_75_3_0_with_degenerate score 0.9651416122\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.2 num_round = 50\n",
      "training_depth_9_eta_0.2_num_boost_round_50_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.2_num_boost_round_50_3_0_with_degenerate score 0.967320261438\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.2 num_round = 55\n",
      "training_depth_9_eta_0.2_num_boost_round_55_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.2_num_boost_round_55_3_0_with_degenerate score 0.971677559913\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.2 num_round = 60\n",
      "training_depth_9_eta_0.2_num_boost_round_60_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.2_num_boost_round_60_3_0_with_degenerate score 0.971677559913\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.2 num_round = 65\n",
      "training_depth_9_eta_0.2_num_boost_round_65_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.2_num_boost_round_65_3_0_with_degenerate score 0.971677559913\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.2 num_round = 70\n",
      "training_depth_9_eta_0.2_num_boost_round_70_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.2_num_boost_round_70_3_0_with_degenerate score 0.971677559913\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.2 num_round = 75\n",
      "training_depth_9_eta_0.2_num_boost_round_75_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.2_num_boost_round_75_3_0_with_degenerate score 0.97385620915\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.3 num_round = 50\n",
      "training_depth_9_eta_0.3_num_boost_round_50_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.3_num_boost_round_50_3_0_with_degenerate score 0.97385620915\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.3 num_round = 55\n",
      "training_depth_9_eta_0.3_num_boost_round_55_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.3_num_boost_round_55_3_0_with_degenerate score 0.97385620915\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.3 num_round = 60\n",
      "training_depth_9_eta_0.3_num_boost_round_60_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.3_num_boost_round_60_3_0_with_degenerate score 0.97385620915\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.3 num_round = 65\n",
      "training_depth_9_eta_0.3_num_boost_round_65_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.3_num_boost_round_65_3_0_with_degenerate score 0.97385620915\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.3 num_round = 70\n",
      "training_depth_9_eta_0.3_num_boost_round_70_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.3_num_boost_round_70_3_0_with_degenerate score 0.97385620915\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 9 eta = 0.3 num_round = 75\n",
      "training_depth_9_eta_0.3_num_boost_round_75_3_0_with_degenerate score 1.0\n",
      "testing_depth_9_eta_0.3_num_boost_round_75_3_0_with_degenerate score 0.97385620915\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 10 eta = 0.05 num_round = 50\n",
      "training_depth_10_eta_0.05_num_boost_round_50_3_0_with_degenerate score 1.0\n",
      "testing_depth_10_eta_0.05_num_boost_round_50_3_0_with_degenerate score 0.952069716776\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 10 eta = 0.05 num_round = 55\n",
      "training_depth_10_eta_0.05_num_boost_round_55_3_0_with_degenerate score 1.0\n",
      "testing_depth_10_eta_0.05_num_boost_round_55_3_0_with_degenerate score 0.954248366013\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 10 eta = 0.05 num_round = 60\n",
      "training_depth_10_eta_0.05_num_boost_round_60_3_0_with_degenerate score 1.0\n",
      "testing_depth_10_eta_0.05_num_boost_round_60_3_0_with_degenerate score 0.954248366013\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 10 eta = 0.05 num_round = 65\n",
      "training_depth_10_eta_0.05_num_boost_round_65_3_0_with_degenerate score 1.0\n",
      "testing_depth_10_eta_0.05_num_boost_round_65_3_0_with_degenerate score 0.954248366013\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 10 eta = 0.05 num_round = 70\n",
      "training_depth_10_eta_0.05_num_boost_round_70_3_0_with_degenerate score 1.0\n",
      "testing_depth_10_eta_0.05_num_boost_round_70_3_0_with_degenerate score 0.958605664488\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 10 eta = 0.05 num_round = 75\n",
      "training_depth_10_eta_0.05_num_boost_round_75_3_0_with_degenerate score 1.0\n",
      "testing_depth_10_eta_0.05_num_boost_round_75_3_0_with_degenerate score 0.962962962963\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 10 eta = 0.1 num_round = 50\n",
      "training_depth_10_eta_0.1_num_boost_round_50_3_0_with_degenerate score 1.0\n",
      "testing_depth_10_eta_0.1_num_boost_round_50_3_0_with_degenerate score 0.9651416122\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 10 eta = 0.1 num_round = 55\n",
      "training_depth_10_eta_0.1_num_boost_round_55_3_0_with_degenerate score 1.0\n",
      "testing_depth_10_eta_0.1_num_boost_round_55_3_0_with_degenerate score 0.962962962963\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 10 eta = 0.1 num_round = 60\n",
      "training_depth_10_eta_0.1_num_boost_round_60_3_0_with_degenerate score 1.0\n",
      "testing_depth_10_eta_0.1_num_boost_round_60_3_0_with_degenerate score 0.962962962963\n",
      "Train size : 1832 Test Size = 459\n",
      "depth = 10 eta = 0.1 num_round = 65\n",
      "training_depth_10_eta_0.1_num_boost_round_65_3_0_with_degenerate score 1.0\n",
      "testing_depth_10_eta_0.1_num_boost_round_65_3_0_with_degenerate score 0.962962962963\n",
      "Train size : 1832 Test Size = 459\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-9b570dc26b66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_boost_round'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mscore_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore_testing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_absolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_Train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_Train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mstr_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'training_depth_{}_eta_{}_num_boost_round_{}_3_0_with_degenerate'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_round\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mstr_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'testing_depth_{}_eta_{}_num_boost_round_{}_3_0_with_degenerate'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_round\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-541d4915c642>\u001b[0m in \u001b[0;36mtrain_absolute\u001b[0;34m(param, X, y, X_test, y_test)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/deepak/01d1aa67-17b4-4928-9c4a-de46eed0333d/usr/naman/anaconda2/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/deepak/01d1aa67-17b4-4928-9c4a-de46eed0333d/usr/naman/anaconda2/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/deepak/01d1aa67-17b4-4928-9c4a-de46eed0333d/usr/naman/anaconda2/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 895\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    896\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(max_depth_arr)\n",
    "print(eta_arr)\n",
    "print(num_rounds_arr)\n",
    "\n",
    "for depth in max_depth_arr :\n",
    "    for eta in eta_arr:\n",
    "        for num_round in num_rounds_arr:\n",
    "            param['eta'] = eta\n",
    "            param['max_depth'] = depth\n",
    "            param['num_boost_round'] = num_round\n",
    "            \n",
    "            score_training,score_testing = train_absolute(param,X_Train,y_Train,X_valid,y_valid)\n",
    "            str_1 = 'training_depth_{}_eta_{}_num_boost_round_{}_3_0_with_degenerate'.format(param['max_depth'],param['eta'],num_round)\n",
    "            str_2 = 'testing_depth_{}_eta_{}_num_boost_round_{}_3_0_with_degenerate'.format(param['max_depth'],param['eta'],num_round)\n",
    "            \n",
    "            dict_res_3_0_pareto[str_1] = score_training\n",
    "            dict_res_3_0_pareto[str_2] = score_testing\n",
    "            \n",
    "            print(\"depth = {} eta = {} num_round = {}\".format(depth,eta,num_round))\n",
    "            print('{} score {}'.format(str_1,score_training))\n",
    "            print('{} score {}'.format(str_2,score_testing))\n",
    "#             print(dict_res_3_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interrupted the above session. Lets see the output so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'testing_depth_10_eta_0.05_num_boost_round_50_3_0_with_degenerate': 0.9520697167755992,\n",
       " 'testing_depth_10_eta_0.05_num_boost_round_55_3_0_with_degenerate': 0.954248366013072,\n",
       " 'testing_depth_10_eta_0.05_num_boost_round_60_3_0_with_degenerate': 0.954248366013072,\n",
       " 'testing_depth_10_eta_0.05_num_boost_round_65_3_0_with_degenerate': 0.954248366013072,\n",
       " 'testing_depth_10_eta_0.05_num_boost_round_70_3_0_with_degenerate': 0.9586056644880174,\n",
       " 'testing_depth_10_eta_0.05_num_boost_round_75_3_0_with_degenerate': 0.9629629629629629,\n",
       " 'testing_depth_10_eta_0.1_num_boost_round_50_3_0_with_degenerate': 0.9651416122004357,\n",
       " 'testing_depth_10_eta_0.1_num_boost_round_55_3_0_with_degenerate': 0.9629629629629629,\n",
       " 'testing_depth_10_eta_0.1_num_boost_round_60_3_0_with_degenerate': 0.9629629629629629,\n",
       " 'testing_depth_10_eta_0.1_num_boost_round_65_3_0_with_degenerate': 0.9629629629629629,\n",
       " 'testing_depth_7_eta_0.05_num_boost_round_50_3_0_with_degenerate': 0.954248366013072,\n",
       " 'testing_depth_7_eta_0.05_num_boost_round_55_3_0_with_degenerate': 0.9564270152505446,\n",
       " 'testing_depth_7_eta_0.05_num_boost_round_60_3_0_with_degenerate': 0.9564270152505446,\n",
       " 'testing_depth_7_eta_0.05_num_boost_round_65_3_0_with_degenerate': 0.9586056644880174,\n",
       " 'testing_depth_7_eta_0.05_num_boost_round_70_3_0_with_degenerate': 0.9607843137254902,\n",
       " 'testing_depth_7_eta_0.05_num_boost_round_75_3_0_with_degenerate': 0.9586056644880174,\n",
       " 'testing_depth_7_eta_0.1_num_boost_round_50_3_0_with_degenerate': 0.9586056644880174,\n",
       " 'testing_depth_7_eta_0.1_num_boost_round_55_3_0_with_degenerate': 0.9586056644880174,\n",
       " 'testing_depth_7_eta_0.1_num_boost_round_60_3_0_with_degenerate': 0.9607843137254902,\n",
       " 'testing_depth_7_eta_0.1_num_boost_round_65_3_0_with_degenerate': 0.9651416122004357,\n",
       " 'testing_depth_7_eta_0.1_num_boost_round_70_3_0_with_degenerate': 0.9651416122004357,\n",
       " 'testing_depth_7_eta_0.1_num_boost_round_75_3_0_with_degenerate': 0.9651416122004357,\n",
       " 'testing_depth_7_eta_0.2_num_boost_round_50_3_0_with_degenerate': 0.971677559912854,\n",
       " 'testing_depth_7_eta_0.2_num_boost_round_55_3_0_with_degenerate': 0.971677559912854,\n",
       " 'testing_depth_7_eta_0.2_num_boost_round_60_3_0_with_degenerate': 0.971677559912854,\n",
       " 'testing_depth_7_eta_0.2_num_boost_round_65_3_0_with_degenerate': 0.9738562091503268,\n",
       " 'testing_depth_7_eta_0.2_num_boost_round_70_3_0_with_degenerate': 0.9738562091503268,\n",
       " 'testing_depth_7_eta_0.2_num_boost_round_75_3_0_with_degenerate': 0.9738562091503268,\n",
       " 'testing_depth_7_eta_0.3_num_boost_round_50_3_0_with_degenerate': 0.971677559912854,\n",
       " 'testing_depth_7_eta_0.3_num_boost_round_55_3_0_with_degenerate': 0.971677559912854,\n",
       " 'testing_depth_7_eta_0.3_num_boost_round_60_3_0_with_degenerate': 0.971677559912854,\n",
       " 'testing_depth_7_eta_0.3_num_boost_round_65_3_0_with_degenerate': 0.971677559912854,\n",
       " 'testing_depth_7_eta_0.3_num_boost_round_70_3_0_with_degenerate': 0.971677559912854,\n",
       " 'testing_depth_7_eta_0.3_num_boost_round_75_3_0_with_degenerate': 0.9738562091503268,\n",
       " 'testing_depth_8_eta_0.05_num_boost_round_50_3_0_with_degenerate': 0.9520697167755992,\n",
       " 'testing_depth_8_eta_0.05_num_boost_round_55_3_0_with_degenerate': 0.954248366013072,\n",
       " 'testing_depth_8_eta_0.05_num_boost_round_60_3_0_with_degenerate': 0.954248366013072,\n",
       " 'testing_depth_8_eta_0.05_num_boost_round_65_3_0_with_degenerate': 0.954248366013072,\n",
       " 'testing_depth_8_eta_0.05_num_boost_round_70_3_0_with_degenerate': 0.954248366013072,\n",
       " 'testing_depth_8_eta_0.05_num_boost_round_75_3_0_with_degenerate': 0.9586056644880174,\n",
       " 'testing_depth_8_eta_0.1_num_boost_round_50_3_0_with_degenerate': 0.9651416122004357,\n",
       " 'testing_depth_8_eta_0.1_num_boost_round_55_3_0_with_degenerate': 0.9651416122004357,\n",
       " 'testing_depth_8_eta_0.1_num_boost_round_60_3_0_with_degenerate': 0.9651416122004357,\n",
       " 'testing_depth_8_eta_0.1_num_boost_round_65_3_0_with_degenerate': 0.9651416122004357,\n",
       " 'testing_depth_8_eta_0.1_num_boost_round_70_3_0_with_degenerate': 0.9651416122004357,\n",
       " 'testing_depth_8_eta_0.1_num_boost_round_75_3_0_with_degenerate': 0.9651416122004357,\n",
       " 'testing_depth_8_eta_0.2_num_boost_round_50_3_0_with_degenerate': 0.9673202614379085,\n",
       " 'testing_depth_8_eta_0.2_num_boost_round_55_3_0_with_degenerate': 0.9694989106753813,\n",
       " 'testing_depth_8_eta_0.2_num_boost_round_60_3_0_with_degenerate': 0.9694989106753813,\n",
       " 'testing_depth_8_eta_0.2_num_boost_round_65_3_0_with_degenerate': 0.9694989106753813,\n",
       " 'testing_depth_8_eta_0.2_num_boost_round_70_3_0_with_degenerate': 0.9738562091503268,\n",
       " 'testing_depth_8_eta_0.2_num_boost_round_75_3_0_with_degenerate': 0.9738562091503268,\n",
       " 'testing_depth_8_eta_0.3_num_boost_round_50_3_0_with_degenerate': 0.9738562091503268,\n",
       " 'testing_depth_8_eta_0.3_num_boost_round_55_3_0_with_degenerate': 0.9738562091503268,\n",
       " 'testing_depth_8_eta_0.3_num_boost_round_60_3_0_with_degenerate': 0.9738562091503268,\n",
       " 'testing_depth_8_eta_0.3_num_boost_round_65_3_0_with_degenerate': 0.9738562091503268,\n",
       " 'testing_depth_8_eta_0.3_num_boost_round_70_3_0_with_degenerate': 0.9738562091503268,\n",
       " 'testing_depth_8_eta_0.3_num_boost_round_75_3_0_with_degenerate': 0.9738562091503268,\n",
       " 'testing_depth_9_eta_0.05_num_boost_round_50_3_0_with_degenerate': 0.9498910675381264,\n",
       " 'testing_depth_9_eta_0.05_num_boost_round_55_3_0_with_degenerate': 0.954248366013072,\n",
       " 'testing_depth_9_eta_0.05_num_boost_round_60_3_0_with_degenerate': 0.954248366013072,\n",
       " 'testing_depth_9_eta_0.05_num_boost_round_65_3_0_with_degenerate': 0.954248366013072,\n",
       " 'testing_depth_9_eta_0.05_num_boost_round_70_3_0_with_degenerate': 0.9586056644880174,\n",
       " 'testing_depth_9_eta_0.05_num_boost_round_75_3_0_with_degenerate': 0.9586056644880174,\n",
       " 'testing_depth_9_eta_0.1_num_boost_round_50_3_0_with_degenerate': 0.9607843137254902,\n",
       " 'testing_depth_9_eta_0.1_num_boost_round_55_3_0_with_degenerate': 0.9607843137254902,\n",
       " 'testing_depth_9_eta_0.1_num_boost_round_60_3_0_with_degenerate': 0.9651416122004357,\n",
       " 'testing_depth_9_eta_0.1_num_boost_round_65_3_0_with_degenerate': 0.9651416122004357,\n",
       " 'testing_depth_9_eta_0.1_num_boost_round_70_3_0_with_degenerate': 0.9629629629629629,\n",
       " 'testing_depth_9_eta_0.1_num_boost_round_75_3_0_with_degenerate': 0.9651416122004357,\n",
       " 'testing_depth_9_eta_0.2_num_boost_round_50_3_0_with_degenerate': 0.9673202614379085,\n",
       " 'testing_depth_9_eta_0.2_num_boost_round_55_3_0_with_degenerate': 0.971677559912854,\n",
       " 'testing_depth_9_eta_0.2_num_boost_round_60_3_0_with_degenerate': 0.971677559912854,\n",
       " 'testing_depth_9_eta_0.2_num_boost_round_65_3_0_with_degenerate': 0.971677559912854,\n",
       " 'testing_depth_9_eta_0.2_num_boost_round_70_3_0_with_degenerate': 0.971677559912854,\n",
       " 'testing_depth_9_eta_0.2_num_boost_round_75_3_0_with_degenerate': 0.9738562091503268,\n",
       " 'testing_depth_9_eta_0.3_num_boost_round_50_3_0_with_degenerate': 0.9738562091503268,\n",
       " 'testing_depth_9_eta_0.3_num_boost_round_55_3_0_with_degenerate': 0.9738562091503268,\n",
       " 'testing_depth_9_eta_0.3_num_boost_round_60_3_0_with_degenerate': 0.9738562091503268,\n",
       " 'testing_depth_9_eta_0.3_num_boost_round_65_3_0_with_degenerate': 0.9738562091503268,\n",
       " 'testing_depth_9_eta_0.3_num_boost_round_70_3_0_with_degenerate': 0.9738562091503268,\n",
       " 'testing_depth_9_eta_0.3_num_boost_round_75_3_0_with_degenerate': 0.9738562091503268,\n",
       " 'training_depth_10_eta_0.05_num_boost_round_50_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_10_eta_0.05_num_boost_round_55_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_10_eta_0.05_num_boost_round_60_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_10_eta_0.05_num_boost_round_65_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_10_eta_0.05_num_boost_round_70_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_10_eta_0.05_num_boost_round_75_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_10_eta_0.1_num_boost_round_50_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_10_eta_0.1_num_boost_round_55_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_10_eta_0.1_num_boost_round_60_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_10_eta_0.1_num_boost_round_65_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_7_eta_0.05_num_boost_round_50_3_0_with_degenerate': 0.9994541484716157,\n",
       " 'training_depth_7_eta_0.05_num_boost_round_55_3_0_with_degenerate': 0.9994541484716157,\n",
       " 'training_depth_7_eta_0.05_num_boost_round_60_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_7_eta_0.05_num_boost_round_65_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_7_eta_0.05_num_boost_round_70_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_7_eta_0.05_num_boost_round_75_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_7_eta_0.1_num_boost_round_50_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_7_eta_0.1_num_boost_round_55_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_7_eta_0.1_num_boost_round_60_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_7_eta_0.1_num_boost_round_65_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_7_eta_0.1_num_boost_round_70_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_7_eta_0.1_num_boost_round_75_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_7_eta_0.2_num_boost_round_50_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_7_eta_0.2_num_boost_round_55_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_7_eta_0.2_num_boost_round_60_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_7_eta_0.2_num_boost_round_65_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_7_eta_0.2_num_boost_round_70_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_7_eta_0.2_num_boost_round_75_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_7_eta_0.3_num_boost_round_50_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_7_eta_0.3_num_boost_round_55_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_7_eta_0.3_num_boost_round_60_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_7_eta_0.3_num_boost_round_65_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_7_eta_0.3_num_boost_round_70_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_7_eta_0.3_num_boost_round_75_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.05_num_boost_round_50_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.05_num_boost_round_55_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.05_num_boost_round_60_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.05_num_boost_round_65_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.05_num_boost_round_70_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.05_num_boost_round_75_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.1_num_boost_round_50_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.1_num_boost_round_55_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.1_num_boost_round_60_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.1_num_boost_round_65_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.1_num_boost_round_70_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.1_num_boost_round_75_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.2_num_boost_round_50_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.2_num_boost_round_55_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.2_num_boost_round_60_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.2_num_boost_round_65_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.2_num_boost_round_70_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.2_num_boost_round_75_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.3_num_boost_round_50_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.3_num_boost_round_55_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.3_num_boost_round_60_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.3_num_boost_round_65_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.3_num_boost_round_70_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_8_eta_0.3_num_boost_round_75_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.05_num_boost_round_50_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.05_num_boost_round_55_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.05_num_boost_round_60_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.05_num_boost_round_65_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.05_num_boost_round_70_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.05_num_boost_round_75_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.1_num_boost_round_50_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.1_num_boost_round_55_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.1_num_boost_round_60_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.1_num_boost_round_65_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.1_num_boost_round_70_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.1_num_boost_round_75_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.2_num_boost_round_50_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.2_num_boost_round_55_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.2_num_boost_round_60_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.2_num_boost_round_65_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.2_num_boost_round_70_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.2_num_boost_round_75_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.3_num_boost_round_50_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.3_num_boost_round_55_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.3_num_boost_round_60_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.3_num_boost_round_65_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.3_num_boost_round_70_3_0_with_degenerate': 1.0,\n",
       " 'training_depth_9_eta_0.3_num_boost_round_75_3_0_with_degenerate': 1.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_res_3_0_pareto"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
